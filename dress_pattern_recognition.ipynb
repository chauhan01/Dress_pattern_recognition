{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dress_pattern_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLKk3l8XlJTc",
        "colab_type": "text"
      },
      "source": [
        "Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku5skad2n1UO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpfhYZ3ZWlAx",
        "colab_type": "text"
      },
      "source": [
        "You can Download the dataset from Here: https://data.world/crowdflower/categorization-dress-patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5dmSaQMlRFv",
        "colab_type": "text"
      },
      "source": [
        "Reading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo_koHz0n3ZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/My Drive/internship/dress_patterns.csv\")\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymBd9PjxTd3A",
        "colab_type": "text"
      },
      "source": [
        "## **Downloading images from the urls**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXYpxQ1WpmvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "import urllib\n",
        "import os\n",
        "if not os.path.exists(\"/content/drive/My Drive/internship/images\"):\n",
        "  os.mkdir(\"/content/drive/My Drive/internship/images\")\n",
        "\n",
        "# creating an empty list to store image names\n",
        "img_name = []\n",
        "path = \"/content/drive/My Drive/internship/images/\"\n",
        "for url in tqdm(data.image_url):\n",
        "  name = url.split('/')[-1]\n",
        "  p = os.path.join(path, name)\n",
        "\n",
        "  # In case execution of the cell is interrupted, re-running the cell will start downloading all the images again\n",
        "  # creating a loop to avoid re-downloading of the downloded images and resume downloading from the last point. \n",
        "  if os.path.exists(p):\n",
        "    pass\n",
        "  else:\n",
        "    urllib.request.urlretrieve(url,p)\n",
        "  # appending image names to the empty list.\n",
        "  img_name.append(name)\n",
        "\n",
        "# creating a new column conatning image names \n",
        "data[\"image_name\"] = img_name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdlMqBCRVwNC",
        "colab_type": "code",
        "outputId": "77d35fcf-9f98-492c-ab50-c86626beebb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_unit_id</th>\n",
              "      <th>category</th>\n",
              "      <th>category:confidence</th>\n",
              "      <th>image_url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>851505458</td>\n",
              "      <td>ikat</td>\n",
              "      <td>0.3487</td>\n",
              "      <td>http://s3-eu-west-1.amazonaws.com/we-attribute...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>851505459</td>\n",
              "      <td>plain</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>http://s3-eu-west-1.amazonaws.com/we-attribute...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>851505460</td>\n",
              "      <td>polka dot</td>\n",
              "      <td>0.6709</td>\n",
              "      <td>http://s3-eu-west-1.amazonaws.com/we-attribute...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>851505461</td>\n",
              "      <td>plain</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>http://s3-eu-west-1.amazonaws.com/we-attribute...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>851505462</td>\n",
              "      <td>geometry</td>\n",
              "      <td>0.7035</td>\n",
              "      <td>http://s3-eu-west-1.amazonaws.com/we-attribute...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    _unit_id  ...                                          image_url\n",
              "0  851505458  ...  http://s3-eu-west-1.amazonaws.com/we-attribute...\n",
              "1  851505459  ...  http://s3-eu-west-1.amazonaws.com/we-attribute...\n",
              "2  851505460  ...  http://s3-eu-west-1.amazonaws.com/we-attribute...\n",
              "3  851505461  ...  http://s3-eu-west-1.amazonaws.com/we-attribute...\n",
              "4  851505462  ...  http://s3-eu-west-1.amazonaws.com/we-attribute...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVT32eb-npEV",
        "colab_type": "text"
      },
      "source": [
        "## **Data Exploration**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHYy4f8SMesq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROkPN6OdOYM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#picking a random image and ploting it\n",
        "rng = np.random.RandomState()\n",
        "idx = rng.choice(range(data.shape[0]))\n",
        "image = plt.imread(\"/content/drive/My Drive/internship/images/\"+data.iloc[idx].image_name)\n",
        "# fetching the category of the image\n",
        "cat = data.iloc[idx].category\n",
        "print(\"category is \", cat)\n",
        "plt.imshow(image)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG3ppsM7R51m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(data['category'].value_counts())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wz3LUKYx5839",
        "colab_type": "text"
      },
      "source": [
        "## **Preparing Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dY4Q0djIkwpn",
        "colab_type": "text"
      },
      "source": [
        "I am using only 65% of the data for this project and using remaining data as the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxuhLiTFk2Pm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spltting data into train and test\n",
        "msk = np.random.rand(len(data)) < 0.65\n",
        "train_data = data[msk]\n",
        "test_data = data[~msk]\n",
        "print(train_data.shape, test_data.shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbOJ7LT5I3CU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#splitting data into train and validation set\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_x, val_x, train_y, val_y = train_test_split(train_data, train_data.category, test_size = 0.3, random_state = 12 )\n",
        "print(train_x.shape, val_x.shape, train_y.shape, val_y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gT08BFAHh9x7",
        "colab_type": "text"
      },
      "source": [
        "## **Model Building**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRwGwl3o6Geu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import to_categorical\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D\n",
        "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from sklearn.metrics import f1_score\n",
        "from keras.optimizers import RMSprop, SGD\n",
        "from keras.models import Model\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUbNLIWdWHKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining input image size and path\n",
        "img_width, img_height = 256, 256\n",
        "image_path = \"/content/drive/My Drive/internship/images/\"\n",
        "batch_size = 32\n",
        "epochs = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycGZZmsLiJYV",
        "colab_type": "text"
      },
      "source": [
        "Using VGG16 as the base model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPOz25Tus5JY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = VGG16(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2Hh_6Cjs5PH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Adding custom Layers \n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(1024, activation=\"relu\")(x)\n",
        "predictions = Dense(17, activation=\"softmax\")(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFJsxHuxs5VG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating the final model \n",
        "model_final = Model(input = base_model.input, output = predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwdMslyvKVmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# making first few layers non trainable\n",
        "for layer in base_model.layers[:5]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGyX9_d3s5Xx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the model \n",
        "model_final.compile(loss = \"categorical_crossentropy\", optimizer = SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI6Jm8U6s5dj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initiate the train and validation generators with data Augumentation \n",
        "aug = ImageDataGenerator(\n",
        "rescale = 1./255,\n",
        "horizontal_flip = True,\n",
        "fill_mode = \"nearest\",\n",
        "zoom_range = 0.3,\n",
        "width_shift_range = 0.3,\n",
        "height_shift_range=0.3,\n",
        "rotation_range=30)\n",
        "\n",
        "train_generator = aug.flow_from_dataframe(\n",
        "train_x, directory=image_path, x_col=\"image_name\", y_col=\"category\",\n",
        "target_size = (img_height, img_width),\n",
        "batch_size = batch_size, \n",
        "class_mode = \"categorical\")\n",
        "\n",
        "validation_generator = aug.flow_from_dataframe(\n",
        "val_x, directory=image_path, x_col=\"image_name\", y_col=\"category\",\n",
        "target_size = (img_height, img_width),\n",
        "class_mode = \"categorical\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8ZPU7sihv3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving class indices for future use\n",
        "import csv\n",
        "w = csv.writer(open(\"/content/drive/My Drive/internship/class_mapping.csv\", \"w\"))\n",
        "for key, val in train_generator.class_indices.items():\n",
        "  w.writerow([key, val])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqTzi4ILivr0",
        "colab_type": "text"
      },
      "source": [
        "Creating model checkpoint to resume training from the previous checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k_GqdCfs5jp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the model according to the conditions\n",
        "checkpoint_path = \"/content/drive/My Drive/internship/vgg16_2.h5\"  \n",
        "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1rortbnhjqU",
        "colab_type": "text"
      },
      "source": [
        "### **Model Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUlrptuYgDnZ",
        "colab_type": "text"
      },
      "source": [
        "Loading the last model checkpoint if exist else start training from the beginning ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHVzpjBrcaCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# check if model previously trained model checkpoint exist\n",
        "if os.path.exists(checkpoint_path):\n",
        "  # loading the checkpoint\n",
        "  model_final = load_model(checkpoint_path)\n",
        "else:\n",
        "  pass\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z8PZ9R9s5pv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training the model \n",
        "model_final.fit_generator(\n",
        "train_generator,\n",
        "steps_per_epoch=len(train_x) / batch_size,\n",
        "epochs = epochs,\n",
        "validation_data = validation_generator,\n",
        "\n",
        "callbacks = [checkpoint, early])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4iSIm4dEXh2",
        "colab_type": "text"
      },
      "source": [
        "# **Model Testing**\n",
        "\n",
        "If you don't want to train the model, you can directly download the trained model from here: https://drive.google.com/open?id=1J7yvBZTtM-MrSiAIWymwt_CbVbdxBgMj and class mapping file from here: https://drive.google.com/open?id=1-EHTb2MxShqOlcrDvXcByxdb7tbQUvK_ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsSAyh4PuVAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading model and reding class mapping csv file\n",
        "model = load_model('/content/drive/My Drive/internship/vgg16_2.h5')\n",
        "with open('/content/drive/My Drive/internship/class_mapping.csv', mode='r') as infile:\n",
        "  reader = csv.reader(infile)\n",
        "  class_indices = {rows[0]:int(rows[1]) for rows in reader}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn0f11VzXwgg",
        "colab_type": "text"
      },
      "source": [
        "The below cell takes path to the image you want to test and returns the prediction along with the image of 5 other similar items."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx8rWVvss5mz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_file = input(\"enter image path \")\n",
        "\n",
        "# Defining a function to make prediction on the input image\n",
        "def pred(path):\n",
        "  image = plt.imread(path, cv2.IMREAD_COLOR)  #reading image\n",
        "  image = cv2.resize(image,(256,256))         #resizing image\n",
        "  image = np.array(image)/255                 #rescaling image\n",
        "  np_image = np.expand_dims(image, axis = 0)  # expanding dimension because our model takes 4d input\n",
        "  pred = model.predict(np_image)        # making prediction\n",
        "  pred = pred.argmax(axis=-1)\n",
        "\n",
        "  # getting the label of the predicted category\n",
        "  label = dict((k,v) for v,k in class_indices.items())\n",
        "  prednames = [label[k] for k in pred][0]\n",
        "  print(\"Dress pattern category is\",prednames)\n",
        "  plt.imshow(image)\n",
        "\n",
        "  # Fetching data for the similar images for the orignal dataframe\n",
        "  fetch = data.loc[data['category']== prednames]\n",
        "  similar_images = np.random.choice(fetch['image_name'], size = 5)  # selecting 5 randoma images\n",
        "  \n",
        "  #reading the similar images\n",
        "  images = []\n",
        "  for i in similar_images:\n",
        "    img = plt.imread('/content/drive/My Drive/internship/images/'+i)\n",
        "    images.append(img)\n",
        "\n",
        "  #Ploting the similar images\n",
        "  fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=(15,5))\n",
        "  fig.suptitle('Here are some dress with similar pattern', fontsize=20)\n",
        "  ax1.imshow(images[0])\n",
        "  ax2.imshow(images[1])\n",
        "  ax3.imshow(images[2])\n",
        "  ax4.imshow(images[3])\n",
        "  ax5.imshow(images[4])\n",
        "\n",
        "# calling the function\n",
        "pred(image_file)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
